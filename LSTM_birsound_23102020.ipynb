{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_birsound.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO2E8Kcim4_Z",
        "outputId": "d548743b-d3e9-4813-98b3-39c7a6c59eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.flush_and_unmount()\n",
        " \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyRnw0e3HeOO"
      },
      "source": [
        "import os, sys\n",
        "sys.path.insert(0,\"/content/drive/My Drive/Colab_PackagesandLibraries\")\n",
        "\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import glob \n",
        "import librosa.display\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import metrics \n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#import wget\n",
        "#!pip install --target=\"/content/drive/My Drive/Colab_PackagesandLibraries\" pytictoc\n",
        "# Install files to spesific directory\n",
        "#url = \"https://ndownloader.figshare.com/files/10853306\"\n",
        "#output_directory = \"/content/drive/My Drive/Datasets/warblrb10k/warblrb10k_public_metadata_2018.csv\"\n",
        "#wget.download(url, out=output_directory)\n",
        "\n",
        "#url = \"https://ndownloader.figshare.com/files/10853303\"\n",
        "#output_directory = \"/content/drive/My Drive/Datasets/ff1010bird/ff1010bird_metadata_2018.csv\"\n",
        "#wget.download(url, out=output_directory)\n",
        "\n",
        "# load data\n",
        "#!wget https://archive.org/download/ff1010bird/ff1010bird_wav.zip\n",
        "\n",
        "#!wget https://archive.org/download/warblrb10k_public/warblrb10k_public_wav.zip\n",
        "\n",
        "# Unzip folder to spesific directory\n",
        "#!unzip ff1010bird_wav.zip -d \"/content/drive/My Drive/Datasets/ff1010bird\"\n",
        "\n",
        "#!unzip warblrb10k_public_wav.zip -d \"/content/drive/My Drive/Datasets/warblrb10k\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xVLcJ61HkTA"
      },
      "source": [
        "datafolder = \"/content/drive/My Drive/Datasets/ff1010bird/\"\n",
        "loc = datafolder+\"wav/\"\n",
        "metadata = pd.read_csv(\"/content/drive/My Drive/Datasets/ff1010bird/ff1010bird_metadata_2018.csv\")\n",
        "m,n = metadata.shape\n",
        "P = 0.05\n",
        "idx = np.random.permutation(m)\n",
        "metadataTrain = metadata.iloc[idx[:round(P*m)]] \n",
        "metadataValidation = metadata.iloc[idx[round(P*m):round(m/10)]]\n",
        "trainFiles = [loc+str(s)+\".wav\" for s in metadataTrain[\"itemid\"]]\n",
        "#print(trainFiles)\n",
        "trainLabels = [str(s) for s in metadataTrain[\"hasbird\"]]\n",
        "#print(trainLabels)\n",
        "validationFiles = [loc+str(s)+\".wav\" for s in metadataValidation[\"itemid\"]]\n",
        "#print(validationFiles)\n",
        "validationLabels = [str(s) for s in metadataValidation[\"hasbird\"]]\n",
        "#print(validationLabels)\n",
        "trainFiles = np.vstack((trainFiles, trainLabels)).T\n",
        "#print(trainFiles)\n",
        "validationFiles = np.vstack((validationFiles,validationLabels)).T\n",
        "#print(validationFiles)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqqlO2yoHnl_"
      },
      "source": [
        "#from pytictoc import TicToc\n",
        "def extract_features(dir,\n",
        "                     bands=40,frames=41):\n",
        "  def _windows(data, window_size):\n",
        "    start = 0\n",
        "    while start < len(data):\n",
        "      yield int(start), int(start + window_size)\n",
        "      start += (window_size // 2)\n",
        "\n",
        "          \n",
        "  window_size = 512 * (frames - 1)\n",
        "  features, labels = [], []\n",
        "  for fn in dir:\n",
        "    segment_log_specgrams, segment_labels = [], []\n",
        "    sound_clip,sr = librosa.load(fn[0])\n",
        "    label = fn[1]\n",
        "    for (start,end) in _windows(sound_clip,window_size):\n",
        "      if(len(sound_clip[start:end]) == window_size):\n",
        "        signal = sound_clip[start:end]\n",
        "        melspec = librosa.feature.melspectrogram(signal,n_mels=bands)\n",
        "        logspec = librosa.amplitude_to_db(melspec)\n",
        "        logspec = logspec.T.flatten()[:, np.newaxis].T\n",
        "        segment_log_specgrams.append(logspec)\n",
        "        segment_labels.append(label)\n",
        "            \n",
        "    segment_log_specgrams = np.asarray(segment_log_specgrams).reshape(\n",
        "                len(segment_log_specgrams),bands,frames,1)\n",
        "    segment_features = np.concatenate((segment_log_specgrams, np.zeros(\n",
        "                np.shape(segment_log_specgrams))), axis=3)\n",
        "    for i in range(len(segment_features)): \n",
        "      segment_features[i, :, :, 1] = librosa.feature.delta(\n",
        "                    segment_features[i, :, :, 0]) \n",
        "    if len(segment_features) > 0: # check for empty segments \n",
        "      features.append(segment_features)\n",
        "      labels.append(segment_labels)\n",
        "  return features, labels\n",
        "\n",
        "#os.chdir(\"/content/drive/My Drive/Datasets/ff1010bird/wav/125557.wav\")\n",
        "\n",
        "#print(trainFiles[0][0])\n",
        "sc, sr = librosa.load(\"/content/drive/My Drive/Datasets/ff1010bird/wav/191742.wav\")\n",
        "#ti = TicToc() # create TicToc instance\n",
        "#ti.tic() # Start timer\n",
        "#print(trainFiles[0][1])\n",
        "trainfeatureVectors, trainVectorLabels=extract_features(trainFiles)\n",
        "ValidationfeatureVectors, ValidationVectorLabels=extract_features(validationFiles)\n",
        "#ti.toc() # Print elapsed time\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj8qHUWTHqgA",
        "outputId": "3d466ddd-f245-4c17-9e0a-c53e6a002e63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "source": [
        "trainVectorLabels = np.array(trainVectorLabels).flatten()\n",
        "trainVectorLabels = trainVectorLabels.reshape(len(trainVectorLabels),1)\n",
        "ValidationVectorLabels = np.array(ValidationVectorLabels).flatten()\n",
        "ValidationVectorLabels = ValidationVectorLabels.reshape(len(ValidationVectorLabels),1)\n",
        "\n",
        "trainfeatureVectors_flat = np.array(trainfeatureVectors).flatten()\n",
        "trainfeatureVectors_flat = trainfeatureVectors_flat.reshape(int(trainfeatureVectors_flat.shape[0]/len(trainVectorLabels)),len(trainVectorLabels))\n",
        "\n",
        "norm = np.linalg.norm(trainfeatureVectors_flat)\n",
        "trainfeatureVectors_flat = trainfeatureVectors_flat/norm #########\n",
        "\n",
        "print(trainfeatureVectors_flat)\n",
        "print(trainfeatureVectors_flat.shape)\n",
        "#trainVectorLabels_flat = trainfeatureVectors.flatten()\n",
        "ValidationfeatureVectors_flat = np.array(ValidationfeatureVectors).flatten()\n",
        "ValidationfeatureVectors_flat = ValidationfeatureVectors_flat.reshape(int(ValidationfeatureVectors_flat.shape[0]/len(ValidationVectorLabels)),len(ValidationVectorLabels))\n",
        "norm = np.linalg.norm(ValidationfeatureVectors_flat)\n",
        "ValidationfeatureVectors_flat = ValidationfeatureVectors_flat/norm #########\n",
        "print(ValidationfeatureVectors_flat)\n",
        "print(ValidationfeatureVectors_flat.shape)\n",
        "\n",
        "#ValidationVectorLabels = trainfeatureVectors.flatten()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.21848063e-05 -9.20912121e-06  1.74555051e-04 ...  5.74748122e-05\n",
            "  -9.89949490e-05  6.22699317e-05]\n",
            " [ 6.06143039e-05  5.51667834e-05  1.62028690e-04 ...  5.91952539e-05\n",
            "  -1.07809017e-04  6.58803147e-05]\n",
            " [ 6.52662509e-06  5.84280133e-05  1.13577403e-04 ...  3.00307855e-05\n",
            "  -1.45454023e-04  3.00307855e-05]\n",
            " ...\n",
            " [ 1.76113497e-04  1.90961197e-05  1.56546946e-04 ...  8.73497155e-05\n",
            "  -3.28699955e-04  8.98937804e-05]\n",
            " [ 1.98845229e-04  8.09629628e-05  2.62681626e-04 ...  7.78351024e-05\n",
            "  -3.01176930e-04  8.11280226e-05]\n",
            " [ 2.73941145e-04  7.90689138e-05  2.43023817e-04 ... -2.24123620e-20\n",
            "  -3.75275269e-04 -2.24123620e-20]]\n",
            "(3280, 7680)\n",
            "[[-3.41465913e-05  1.63758154e-05  3.46432544e-05 ... -1.61693860e-05\n",
            "   5.99906694e-06 -2.24223989e-05]\n",
            " [-6.30704039e-05 -2.24223989e-05 -1.40611006e-04 ... -9.33300518e-06\n",
            "  -1.53701374e-04 -7.33440962e-06]\n",
            " [-1.96741342e-04 -1.73227789e-05 -3.69395919e-04 ... -1.99872855e-05\n",
            "  -3.15611515e-04 -5.08602979e-06]\n",
            " ...\n",
            " [-1.90184728e-04 -2.05503130e-05 -2.11534319e-04 ... -6.75555340e-06\n",
            "  -3.00939770e-04 -5.11491014e-06]\n",
            " [-3.35047941e-04 -7.51410257e-06 -3.19938786e-04 ... -1.77845348e-06\n",
            "  -3.29703608e-04 -1.77845348e-06]\n",
            " [-3.29703608e-04 -1.77845348e-06 -3.29703608e-04 ... -2.76479007e-20\n",
            "  -3.24607408e-04 -2.76479007e-20]]\n",
            "(3280, 7700)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ILEeHpEHvAD"
      },
      "source": [
        "# trainfeatureVectors = np.concatenate(trainfeatureVectors)\n",
        "# repeat_num = len(trainfeatureVectors[1])\n",
        "# trainfeatureVectors = np.concatenate(trainfeatureVectors)\n",
        "# trainVectorLabels = np.concatenate(trainVectorLabels)\n",
        "# trainVectorLabels = np.tile(trainVectorLabels, (repeat_num, 1))\n",
        "# trainVectorLabels = np.concatenate(trainVectorLabels)\n",
        "# ValidationfeatureVectors = np.concatenate(ValidationfeatureVectors)\n",
        "# ValidationfeatureVectors = np.concatenate(ValidationfeatureVectors)\n",
        "# ValidationVectorLabels = np.concatenate(ValidationVectorLabels)\n",
        "# ValidationVectorLabels = np.tile(ValidationVectorLabels, (repeat_num, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWn6PMdpHyAt"
      },
      "source": [
        "#print(trainfeatureVectors.shape)\n",
        "#print(trainVectorLabels.shape)\n",
        "#print(ValidationfeatureVectors.shape)\n",
        "#print(ValidationVectorLabels.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P2YUu7jH02F"
      },
      "source": [
        "\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(trainfeatureVectors_flat.shape[0])),\n",
        "        # tf.keras.layers.experimental.RandomFourierFeatures(\n",
        "        #     output_dim=4096, scale=10.0, kernel_initializer=\"gaussian\"\n",
        "        # ),\n",
        "        tf.keras.layers.Dense(512, activation= \"relu\"),\n",
        "        tf.keras.layers.Dense(256, activation = \"linear\"),\n",
        "        tf.keras.layers.Dense(256, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(256, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(64, activation = \"linear\"),\n",
        "        tf.keras.layers.Dense(64, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(64, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(32, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(16, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(1, activation = \"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruF--bkX-emL",
        "outputId": "8be398eb-a3aa-4f03-ecfb-3a87cce5e06d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        }
      },
      "source": [
        "history = model.fit(trainfeatureVectors_flat.T.astype(np.float),trainVectorLabels.astype(np.float),batch_size = 512,epochs=50,verbose=0,shuffle=True)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Evaluate random veriyor\n",
        "test_loss, test_acc = model.evaluate(ValidationfeatureVectors_flat.T.astype(np.float), ValidationVectorLabels.astype(np.float))\n",
        "predictions = model.predict(ValidationfeatureVectors_flat.T.astype(np.float))\n",
        "\n",
        "# predictions = model.predict(ValidationfeatureVectors_flat.T.astype(np.float))\n",
        "\n",
        "# print(test_acc)\n",
        "\n",
        "print(predictions)\n",
        "# print(ValidationVectorLabels)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_266 (Dense)            (None, 512)               1679872   \n",
            "_________________________________________________________________\n",
            "dense_267 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_268 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_269 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_270 (Dense)            (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_271 (Dense)            (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_272 (Dense)            (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_273 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_274 (Dense)            (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_275 (Dense)            (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,970,177\n",
            "Trainable params: 1,970,177\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6961 - binary_accuracy: 0.6684\n",
            "[[0.7220639 ]\n",
            " [0.2769996 ]\n",
            " [0.5977016 ]\n",
            " ...\n",
            " [0.22536668]\n",
            " [0.46044964]\n",
            " [0.22759798]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECohMDWy_WcZ",
        "outputId": "1495efd3-6830-4f6f-857f-fc699d408a56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "# predictions = np.zeros_like(predictions)\n",
        "predictions.shape\n",
        "predictions = (predictions>=0.5)\n",
        "print(predictions)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ True]\n",
            " [False]\n",
            " [ True]\n",
            " ...\n",
            " [False]\n",
            " [False]\n",
            " [False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gACkwosu4jpm",
        "outputId": "426b1062-6920-4ac4-ae99-b6027c8dccea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(ValidationVectorLabels.astype(np.float),predictions)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6684415584415584"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}