{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "birdSoundDetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyRnw0e3HeOO",
        "outputId": "ded28337-d508-4bdc-f91c-8ef90a770370",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Let's start!\\n\")\n",
        "print(\"Loading...\")\n",
        "\n",
        "import glob\n",
        "import random\n",
        "print(\"...\")\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "print(\"...\")\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "print(\"...\")\n",
        "\n",
        "import json\n",
        "print(\"...\")\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "print(\"...\")\n",
        "\n",
        "\n",
        "print(\"Libraries are imported successfully\")\n",
        "\n",
        "#!pip install --target=\"/content/drive/My Drive/Colab_PackagesandLibraries\" wget\n",
        "#import wget\n",
        "\n",
        "# Install files to spesific directory\n",
        "#!wget \"https://ndownloader.figshare.com/files/10853306\"\n",
        "#output_directory = \"/content/drive/My Drive/Datasets/warblrb10k/warblrb10k_public_metadata_2018.csv\"\n",
        "#wget.download(url, out=output_directory)\n",
        "\n",
        "#url= \"https://ndownloader.figshare.com/files/10853303\" \n",
        "#output_directory = \"/content/drive/My Drive/Datasets/ff1010bird/ff1010bird_metadata_2018.csv\"\n",
        "#wget.download(url, out=output_directory)\n",
        "\n",
        "# load data\n",
        "#!wget https://archive.org/download/ff1010bird/ff1010bird_wav.zip\n",
        "\n",
        "#!wget https://archive.org/download/warblrb10k_public/warblrb10k_public_wav.zip\n",
        "\n",
        "# Unzip folder to spesific directory\n",
        "#!unzip ff1010bird_wav.zip -d \"/content/drive/My Drive/Datasets/ff1010bird\"\n",
        "\n",
        "#!unzip warblrb10k_public_wav.zip -d \"/content/drive/My Drive/Datasets/warblrb10k\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's start!\n",
            "\n",
            "Loading...\n",
            "...\n",
            "...\n",
            "...\n",
            "...\n",
            "...\n",
            "Libraries are imported successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ei6gR3zGL--"
      },
      "source": [
        "# Getting the dataset\n",
        "# ff1010bird, warblrb10k\n",
        "datafolder = \"/content/drive/My Drive/Datasets/ff1010bird/\"\n",
        "#datafolder = \"/content/drive/My Drive/Datasets/warblrb10k/\"\n",
        "loc = datafolder+\"wav/\"\n",
        "metadata = pd.read_csv(datafolder+\"metadata.csv\")\n",
        "metadataFiles = [loc+str(s)+\".wav\" for s in metadata[\"itemid\"]]\n",
        "#print(metadataFiles)\n",
        "metadataLabels = [str(s) for s in metadata[\"hasbird\"]]\n",
        "#print(metadataLabels)\n",
        "metadataFiles = np.vstack((metadataFiles, metadataLabels)).T\n",
        "#print(metadataFiles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqqlO2yoHnl_",
        "outputId": "2c2cb76d-bece-4b88-8914-723492b6a18b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Function for extracting features\n",
        "def extract_features(dir,\n",
        "                     bands=40,frames=41):\n",
        "  def _windows(data, window_size):\n",
        "    start = 0\n",
        "    while start < len(data):\n",
        "      yield int(start), int(start + window_size)\n",
        "      start += (window_size // 2)\n",
        "\n",
        "\n",
        "  window_size = 512 * (frames - 1)\n",
        "  features, labels = [], []\n",
        "  for fn in dir:\n",
        "    segment_log_specgrams, segment_labels = [], []\n",
        "    sound_clip,sr = librosa.load(fn[0])\n",
        "    label = fn[1]\n",
        "    for (start,end) in _windows(sound_clip,window_size):\n",
        "      if(len(sound_clip[start:end]) == window_size):\n",
        "        signal = sound_clip[start:end]\n",
        "        melspec = librosa.feature.melspectrogram(signal,n_mels=bands)\n",
        "        logspec = librosa.amplitude_to_db(melspec)\n",
        "        logspec = logspec.T.flatten()[:, np.newaxis].T\n",
        "        segment_log_specgrams.append(logspec)\n",
        "        segment_labels.append(label)\n",
        "\n",
        "    segment_log_specgrams = np.asarray(segment_log_specgrams).reshape(\n",
        "                len(segment_log_specgrams),bands,frames,1)\n",
        "    segment_features = np.concatenate((segment_log_specgrams, np.zeros(\n",
        "                np.shape(segment_log_specgrams))), axis=3)\n",
        "    for i in range(len(segment_features)):\n",
        "      segment_features[i, :, :, 1] = librosa.feature.delta(\n",
        "                    segment_features[i, :, :, 0])\n",
        "    if True:#len(segment_features) > 0: # check for empty segments\n",
        "      if len(labels)==0:\n",
        "        features = segment_features\n",
        "        labels = segment_labels\n",
        "      else:\n",
        "        features = np.concatenate((features,segment_features))\n",
        "        labels =np.concatenate((labels,segment_labels))\n",
        "  return features, labels\n",
        "print(\"What the heck\")\n",
        "# Extracting features from sound files and save them to file\n",
        "\"\"\"for i in range (int (len(metadataFiles)/100)+1):\n",
        "  if (len(metadataFiles)%100)==0 and i==(len(metadataFiles)/100):\n",
        "    break\n",
        "  if i==(len(metadataFiles)/100):\n",
        "    featureVectors, VectorLabels=extract_features(metadataFiles[:][i*100:len(metadataFiles)])\n",
        "  else:\n",
        "    featureVectors, VectorLabels=extract_features(metadataFiles[:][i*100:(i+1)*100])\n",
        "  featureVectors = np.array(featureVectors)\n",
        "  VectorLabels= np.array(VectorLabels)\n",
        "  with open(datafolder+'mfcc_mfccdelta/'+'features_'+str(i)+'.npy', 'wb') as f:\n",
        "    np.save(f,featureVectors)\n",
        "  with open(datafolder+'mfcc_mfccdelta/'+'labels_'+str(i)+'.npy', 'wb') as f:\n",
        "    np.save(f, VectorLabels)\n",
        "  print(str(i))\"\"\"\n",
        "\n",
        "del metadataFiles, metadataLabels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What the heck\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJrYdgmnllW2",
        "outputId": "5fcea3a5-3a23-40b9-9526-87cba575b77a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Load features and labels from trainFiles\n",
        "for i in range (int (len(metadata)/100)+1):\n",
        "  if (len(metadata)%100)==0 and i==(len(metadata)/100):\n",
        "    break\n",
        "  with open(datafolder+'mfcc_mfccdelta/'+'features_'+str(i)+'.npy','rb') as fs:\n",
        "    featureVectorstmp = np.load(fs)\n",
        "  with open(datafolder+'mfcc_mfccdelta/'+'labels_'+str(i)+'.npy','rb') as f:\n",
        "    VectorLabelstmp = np.load(f)\n",
        "  if i==0:\n",
        "    featureVectors=featureVectorstmp\n",
        "    VectorLabels=VectorLabelstmp\n",
        "  else:\n",
        "    featureVectors=np.concatenate((featureVectors,featureVectorstmp))\n",
        "    VectorLabels=np.concatenate((VectorLabels,VectorLabelstmp))\n",
        "  fs.close()\n",
        "  f.close()\n",
        "print(featureVectors.shape)\n",
        "print(\"Features and labels loaded\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(153800, 40, 41, 2)\n",
            "Features and labels loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xVLcJ61HkTA",
        "outputId": "ffe06d00-0d6a-4986-9bd0-4f0a19bfa16e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Determine train and dev sets from the dataset\n",
        "print(len(featureVectors))\n",
        "m = len(VectorLabels)\n",
        "P = 0.9\n",
        "idx = np.random.permutation(m)\n",
        "trainfeatureVectors=featureVectors[idx[:round(P*m)]]\n",
        "trainVectorLabels=VectorLabels[idx[:round(P*m)]]\n",
        "ValidationfeatureVectors=featureVectors[idx[round(P*m):round(m)]]\n",
        "ValidationVectorLabels=VectorLabels[idx[round(P*m):round(m)]]\n",
        "del featureVectors, VectorLabels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj8qHUWTHqgA",
        "outputId": "5a7ceb1b-502e-40bf-8c18-13b566fbb62b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Reshaping (flattening) the extracted features to make them suitable for inserting the model\n",
        "trainVectorLabels = np.array(trainVectorLabels).flatten()\n",
        "trainVectorLabels[:] = np.array(trainVectorLabels[:])\n",
        "trainVectorLabels = trainVectorLabels.reshape(len(trainVectorLabels),1)\n",
        "ValidationVectorLabels = np.array(ValidationVectorLabels).flatten()\n",
        "ValidationVectorLabels = ValidationVectorLabels.reshape(len(ValidationVectorLabels),1)\n",
        "\n",
        "trainfeatureVectors = np.array(trainfeatureVectors).flatten()\n",
        "trainfeatureVectors = trainfeatureVectors.reshape(int(trainfeatureVectors.shape[0]/len(trainVectorLabels)),len(trainVectorLabels))\n",
        "\n",
        "# Normalizing the vector values\n",
        "trainfeatureVectors = trainfeatureVectors/np.linalg.norm(trainfeatureVectors) #########\n",
        "\n",
        "print(\"Dim of feature vectors of training set: \" + str(trainfeatureVectors.shape))\n",
        "\n",
        "ValidationfeatureVectors = np.array(ValidationfeatureVectors).flatten()\n",
        "ValidationfeatureVectors = ValidationfeatureVectors.reshape(int(ValidationfeatureVectors.shape[0]/len(ValidationVectorLabels)),len(ValidationVectorLabels))\n",
        "\n",
        "# Normalizing the vector values\n",
        "ValidationfeatureVectors = ValidationfeatureVectors/np.linalg.norm(ValidationfeatureVectors) #########\n",
        "\n",
        "print(\"Dim of feature vectors of validation set: \" + str(ValidationfeatureVectors.shape))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dim of feature vectors of training set: (3280, 138420)\n",
            "Dim of feature vectors of validation set: (3280, 15380)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P2YUu7jH02F"
      },
      "source": [
        "# Constructing the model\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(trainfeatureVectors.shape[0])),\n",
        "        # tf.keras.layers.experimental.RandomFourierFeatures(\n",
        "        #     output_dim=4096, scale=10.0, kernel_initializer=\"gaussian\"\n",
        "        # ),\n",
        "        tf.keras.layers.Dense(512, activation= \"relu\"),\n",
        "        tf.keras.layers.Dense(256, activation = \"linear\"),\n",
        "        tf.keras.layers.Dense(256, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(256, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(64, activation = \"linear\"),\n",
        "        tf.keras.layers.Dense(64, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(64, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(32, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(16, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(1, activation = \"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU9hB2xavNvi",
        "outputId": "45ef43b6-d25e-4729-e976-5c5ffdd13a0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(trainVectorLabels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNm_4_0cGchQ",
        "outputId": "20ce26f4-acb4-4c27-fac0-aa5fdad3fe27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fitting the training data into the model\n",
        "history = model.fit(trainfeatureVectors.T.astype(np.float),trainVectorLabels.astype(np.float),batch_size = 512,epochs=50,verbose=0,shuffle=True)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#Evaluating and making predictoin with validation set\n",
        "valid_loss, valid_acc = model.evaluate(ValidationfeatureVectors.T.astype(np.float), ValidationVectorLabels.astype(np.float))\n",
        "predictions = model.predict(ValidationfeatureVectors.T.astype(np.float))\n",
        "\n",
        "# predictions = model.predict(ValidationfeatureVectors_flat.T.astype(np.float))\n",
        "\n",
        "print(\"Validation loss: \" + str(valid_loss))\n",
        "print(\"Validation accuracy: \" + str(valid_acc))\n",
        "\n",
        "print(predictions[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               1679872   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,970,177\n",
            "Trainable params: 1,970,177\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "481/481 [==============================] - 2s 5ms/step - loss: 0.5629 - binary_accuracy: 0.7495\n",
            "Validation loss: 0.5629020929336548\n",
            "Validation accuracy: 0.7495448589324951\n",
            "[0.25548488]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDBNamKXXOSU",
        "outputId": "844467f8-39ee-4116-9830-9e2ccb667a5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Binarization of prediction data\n",
        "predictions = (predictions>=0.5)\n",
        "\n",
        "print(predictions[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}