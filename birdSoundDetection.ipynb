{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "birdSoundDetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyRnw0e3HeOO",
        "outputId": "5e3f3995-b437-487a-b148-007619e5c386",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(\"Let's start!\\n\")\n",
        "print(\"Loading...\")\n",
        "\n",
        "import glob\n",
        "import random\n",
        "print(\"...\")\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "print(\"...\")\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "print(\"...\")\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import json\n",
        "import time\n",
        "print(\"...\")\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "print(\"...\")\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "print(\"Libraries are imported successfully\")\n",
        "#import wget\n",
        "#!pip install --target=\"/content/drive/My Drive/Colab_PackagesandLibraries\" pytictoc\n",
        "# Install files to spesific directory\n",
        "#url = \"https://ndownloader.figshare.com/files/10853306\"\n",
        "#output_directory = \"/content/drive/My Drive/Datasets/warblrb10k/warblrb10k_public_metadata_2018.csv\"\n",
        "#wget.download(url, out=output_directory)\n",
        "\n",
        "#url = \"https://ndownloader.figshare.com/files/10853303\"\n",
        "#output_directory = \"/content/drive/My Drive/Datasets/ff1010bird/ff1010bird_metadata_2018.csv\"\n",
        "#wget.download(url, out=output_directory)\n",
        "\n",
        "# load data\n",
        "#!wget https://archive.org/download/ff1010bird/ff1010bird_wav.zip\n",
        "\n",
        "#!wget https://archive.org/download/warblrb10k_public/warblrb10k_public_wav.zip\n",
        "\n",
        "# Unzip folder to spesific directory\n",
        "#!unzip ff1010bird_wav.zip -d \"/content/drive/My Drive/Datasets/ff1010bird\"\n",
        "\n",
        "#!unzip warblrb10k_public_wav.zip -d \"/content/drive/My Drive/Datasets/warblrb10k\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's start!\n",
            "\n",
            "Loading...\n",
            "...\n",
            "...\n",
            "...\n",
            "...\n",
            "...\n",
            "Libraries are imported successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ei6gR3zGL--"
      },
      "source": [
        "# Getting the dataset\n",
        "datafolder = \"/content/drive/My Drive/Datasets/ff1010bird/\"\n",
        "loc = datafolder+\"wav/\"\n",
        "metadata = pd.read_csv(\"/content/drive/My Drive/Datasets/ff1010bird/ff1010bird_metadata_2018.csv\")\n",
        "metadataFiles = [loc+str(s)+\".wav\" for s in metadata[\"itemid\"]]\n",
        "#print(metadataFiles)\n",
        "metadataLabels = [str(s) for s in metadata[\"hasbird\"]]\n",
        "#print(metadataLabels)\n",
        "metadataFiles = np.vstack((metadataFiles, metadataLabels)).T\n",
        "#print(metadataFiles)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqqlO2yoHnl_",
        "outputId": "92bc0030-6ed5-4877-d5b8-4c9a84ac8679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "# Function for extracting features\n",
        "def extract_features(dir,\n",
        "                     bands=40,frames=41):\n",
        "  def _windows(data, window_size):\n",
        "    start = 0\n",
        "    while start < len(data):\n",
        "      yield int(start), int(start + window_size)\n",
        "      start += (window_size // 2)\n",
        "\n",
        "\n",
        "  window_size = 512 * (frames - 1)\n",
        "  features, labels = [], []\n",
        "  for fn in dir:\n",
        "    segment_log_specgrams, segment_labels = [], []\n",
        "    sound_clip,sr = librosa.load(fn[0])\n",
        "    label = fn[1]\n",
        "    for (start,end) in _windows(sound_clip,window_size):\n",
        "      if(len(sound_clip[start:end]) == window_size):\n",
        "        signal = sound_clip[start:end]\n",
        "        melspec = librosa.feature.melspectrogram(signal,n_mels=bands)\n",
        "        logspec = librosa.amplitude_to_db(melspec)\n",
        "        logspec = logspec.T.flatten()[:, np.newaxis].T\n",
        "        segment_log_specgrams.append(logspec)\n",
        "        segment_labels.append(label)\n",
        "\n",
        "    segment_log_specgrams = np.asarray(segment_log_specgrams).reshape(\n",
        "                len(segment_log_specgrams),bands,frames,1)\n",
        "    segment_features = np.concatenate((segment_log_specgrams, np.zeros(\n",
        "                np.shape(segment_log_specgrams))), axis=3)\n",
        "    for i in range(len(segment_features)):\n",
        "      segment_features[i, :, :, 1] = librosa.feature.delta(\n",
        "                    segment_features[i, :, :, 0])\n",
        "    if len(segment_features) > 0: # check for empty segments\n",
        "      features.append(segment_features)\n",
        "      labels.append(segment_labels)\n",
        "  return features, labels\n",
        "print(\"What the heck\")\n",
        "# Extracting features from sound files and save them to file\n",
        "\"\"\"for i in range (int (len(metadataFiles)/100)+1):\n",
        "  if (len(metadataFiles)%100)==0 and i==(len(metadataFiles)/100):\n",
        "    break\n",
        "  if i==(len(metadataFiles)/100):\n",
        "    featureVectors, VectorLabels=extract_features(metadataFiles[:][i*100:len(metadataFiles)])\n",
        "  else:\n",
        "    featureVectors, VectorLabels=extract_features(metadataFiles[:][i*100:(i+1)*100])\n",
        "  featureVectors= np.array(featureVectors).tolist()\n",
        "  VectorLabels= np.array(VectorLabels).tolist()\n",
        "  with open('/content/drive/My Drive/Datasets/ff1010bird/mfcc_mfccdelta/'+'features_'+str(i)+'.json', 'w') as f:\n",
        "    json.dump(featureVectors, f)\n",
        "  with open('/content/drive/My Drive/Datasets/ff1010bird/mfcc_mfccdelta/'+'labels_'+str(i)+'.json', 'w') as f:\n",
        "    json.dump(VectorLabels, f)\n",
        "  print(str(i))\"\"\"\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What the heck\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"for i in range (int (len(metadataFiles)/100)+1):\\n  if (len(metadataFiles)%100)==0 and i==(len(metadataFiles)/100):\\n    break\\n  if i==(len(metadataFiles)/100):\\n    featureVectors, VectorLabels=extract_features(metadataFiles[:][i*100:len(metadataFiles)])\\n  else:\\n    featureVectors, VectorLabels=extract_features(metadataFiles[:][i*100:(i+1)*100])\\n  featureVectors= np.array(featureVectors).tolist()\\n  VectorLabels= np.array(VectorLabels).tolist()\\n  with open('/content/drive/My Drive/Datasets/ff1010bird/mfcc_mfccdelta/'+'features_'+str(i)+'.json', 'w') as f:\\n    json.dump(featureVectors, f)\\n  with open('/content/drive/My Drive/Datasets/ff1010bird/mfcc_mfccdelta/'+'labels_'+str(i)+'.json', 'w') as f:\\n    json.dump(VectorLabels, f)\\n  print(str(i))\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJrYdgmnllW2",
        "outputId": "b8a59f69-d78a-4627-fee1-8d575a826a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Load features and labels from trainFiles\n",
        "for i in range (int (len(metadataFiles)/100)+1):\n",
        "  if (len(metadataFiles)%100)==0 and i==(len(metadataFiles)/100):\n",
        "    break\n",
        "  with open('/content/drive/My Drive/Datasets/ff1010bird/mfcc_mfccdelta/'+'features_'+str(i)+'.json','r') as fs:\n",
        "    featureVectorstmp = json.loads(fs.read())\n",
        "  with open('/content/drive/My Drive/Datasets/ff1010bird/mfcc_mfccdelta/'+'labels_'+str(i)+'.json','r') as f:\n",
        "    VectorLabelstmp = json.loads(f.read())\n",
        "  if i==0:\n",
        "    featureVectors=featureVectorstmp\n",
        "    VectorLabels=VectorLabelstmp\n",
        "  else:\n",
        "    featureVectors=np.concatenate((featureVectors,featureVectorstmp))\n",
        "    VectorLabels=np.concatenate((VectorLabels,VectorLabelstmp))\n",
        "  fs.close()\n",
        "  f.close()\n",
        "print(\"Features and labels loaded\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features and labels loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xVLcJ61HkTA",
        "outputId": "1cb3e964-a1b1-4471-9574-cfc65c3e30b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Determine train and dev sets from the dataset\n",
        "print(len(featureVectors))\n",
        "m = len(VectorLabels)\n",
        "P = 0.9\n",
        "idx = np.random.permutation(m)\n",
        "trainfeatureVectors=featureVectors[idx[:round(P*m)]]\n",
        "trainVectorLabels=VectorLabels[idx[:round(P*m)]]\n",
        "ValidationfeatureVectors=featureVectors[idx[round(P*m):round(m)]]\n",
        "ValidationVectorLabels=VectorLabels[idx[round(P*m):round(m)]]\n",
        "del featureVectors, VectorLabels"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj8qHUWTHqgA",
        "outputId": "eaac6240-f2c3-41b2-8254-279ca3a0d638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Reshaping (flattening) the extracted features to make them suitable for inserting the model\n",
        "trainVectorLabels = np.array(trainVectorLabels).flatten()\n",
        "trainVectorLabels = trainVectorLabels.reshape(len(trainVectorLabels),1)\n",
        "ValidationVectorLabels = np.array(ValidationVectorLabels).flatten()\n",
        "ValidationVectorLabels = ValidationVectorLabels.reshape(len(ValidationVectorLabels),1)\n",
        "\n",
        "trainfeatureVectors = np.array(trainfeatureVectors).flatten()\n",
        "trainfeatureVectors = trainfeatureVectors.reshape(int(trainfeatureVectors.shape[0]/len(trainVectorLabels)),len(trainVectorLabels))\n",
        "\n",
        "# Normalizing the vector values\n",
        "trainfeatureVectors = trainfeatureVectors/np.linalg.norm(trainfeatureVectors) #########\n",
        "\n",
        "print(\"Dim of feature vectors of training set: \" + str(trainfeatureVectors.shape))\n",
        "\n",
        "ValidationfeatureVectors = np.array(ValidationfeatureVectors).flatten()\n",
        "ValidationfeatureVectors = ValidationfeatureVectors.reshape(int(ValidationfeatureVectors.shape[0]/len(ValidationVectorLabels)),len(ValidationVectorLabels))\n",
        "\n",
        "# Normalizing the vector values\n",
        "ValidationfeatureVectors = ValidationfeatureVectors/np.linalg.norm(ValidationfeatureVectors) #########\n",
        "\n",
        "print(\"Dim of feature vectors of validation set: \" + str(ValidationfeatureVectors.shape))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dim of feature vectors of training set: (3280, 138420)\n",
            "Dim of feature vectors of validation set: (3280, 15380)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P2YUu7jH02F"
      },
      "source": [
        "# Constructing the model\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(trainfeatureVectors.shape[0])),\n",
        "        # tf.keras.layers.experimental.RandomFourierFeatures(\n",
        "        #     output_dim=4096, scale=10.0, kernel_initializer=\"gaussian\"\n",
        "        # ),\n",
        "        tf.keras.layers.Dense(512, activation= \"relu\"),\n",
        "        tf.keras.layers.Dense(256, activation = \"linear\"),\n",
        "        tf.keras.layers.Dense(256, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(256, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(64, activation = \"linear\"),\n",
        "        tf.keras.layers.Dense(64, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(64, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(32, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(16, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(1, activation = \"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNm_4_0cGchQ",
        "outputId": "755f03b6-87db-4e77-b185-bd009223a307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "# Fitting the training data into the model\n",
        "history = model.fit(trainfeatureVectors.T.astype(np.float),trainVectorLabels.astype(np.float),batch_size = 512,epochs=50,verbose=0,shuffle=True)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#Evaluating and making predictoin with validation set\n",
        "valid_loss, valid_acc = model.evaluate(ValidationfeatureVectors.T.astype(np.float), ValidationVectorLabels.astype(np.float))\n",
        "predictions = model.predict(ValidationfeatureVectors.T.astype(np.float))\n",
        "\n",
        "# predictions = model.predict(ValidationfeatureVectors_flat.T.astype(np.float))\n",
        "\n",
        "print(\"Validation loss: \" + str(valid_loss))\n",
        "print(\"Validation accuracy: \" + str(valid_acc))\n",
        "\n",
        "print(predictions[0])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               1679872   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,970,177\n",
            "Trainable params: 1,970,177\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "481/481 [==============================] - 3s 5ms/step - loss: 0.5566 - binary_accuracy: 0.7555\n",
            "Validation loss: 0.5565674901008606\n",
            "Validation accuracy: 0.7555266618728638\n",
            "[0.25654888]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDBNamKXXOSU",
        "outputId": "92cb5849-e98b-438d-d878-c04c610411a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Binarization of prediction data\n",
        "predictions = (predictions>=0.5)\n",
        "\n",
        "print(predictions[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}